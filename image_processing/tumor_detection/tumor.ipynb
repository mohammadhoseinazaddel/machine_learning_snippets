{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tumor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Try Prediction using cv2 and preprocessing (crop,resize,convert to gray)**"
      ],
      "metadata": {
        "id": "ITlxlHDAMFdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import imutils\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "EkiqJXkxlspv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pathlib\n",
        "path = pathlib.Path(\"/content/drive/MyDrive/tumor_data\")\n",
        "%cd /content/drive/MyDrive/tumor_data\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwv6ElM4MTbr",
        "outputId": "1e241916-534e-4dd2-bede-7a5fbf6789e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/tumor_data\n",
            "\u001b[0m\u001b[01;34mno\u001b[0m/  \u001b[01;34myes\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ext = ['jpg', 'JPG', 'pnp', 'jpeg']\n",
        "\n",
        "\n",
        "def get_files(path_, ext):\n",
        "    temp_paths = []\n",
        "    [temp_paths.extend(glob.glob(path_ + '*.' + e)) for e in ext]\n",
        "    return temp_paths\n",
        "\n",
        "files_yes = get_files('yes/', ext)\n",
        "files_no = get_files('no/', ext)\n",
        "\n",
        "\n",
        "def read_files(files):\n",
        "    temp_images = []\n",
        "    for file in files:\n",
        "        temp_img = cv2.imread(file)\n",
        "        if temp_img is not None:\n",
        "            temp_images.append(temp_img)\n",
        "    return temp_images\n",
        "\n",
        "tumor_imgs_yes = read_files(files_yes)\n",
        "tumor_imgs_no = read_files(files_no)\n",
        "\n",
        "\n",
        "def crop_brain(image):\n",
        "    \n",
        "    # Convert the image to grayscale, and blur it slightly\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    \n",
        "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "    # Find contours in thresholded image, then grab the largest one\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "    # extreme points\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "    \n",
        "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
        "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
        "    \n",
        "    return new_image\n",
        "\n",
        "\n",
        "tumor_imgs_croped_yes = []\n",
        "tumor_imgs_croped_no = []\n",
        "\n",
        "\n",
        "\n",
        "for image in tumor_imgs_yes:\n",
        "    x = crop_brain(image)\n",
        "    x_resize = cv2.resize(x, (128, 128))\n",
        "    gray = cv2.cvtColor(x_resize, cv2.COLOR_BGR2GRAY)\n",
        "    tumor_imgs_croped_yes.append(gray)\n",
        "\n",
        "\n",
        "for image in tumor_imgs_no:\n",
        "    x = crop_brain(image)\n",
        "    x_resize = cv2.resize(x, (128, 128))\n",
        "    gray = cv2.cvtColor(x_resize, cv2.COLOR_BGR2GRAY)\n",
        "    tumor_imgs_croped_no.append(gray)\n",
        "\n",
        "\n",
        "y_yes = np.ones(len(tumor_imgs_croped_yes), dtype=\"int8\")\n",
        "y_no = np.zeros(len(tumor_imgs_croped_no), dtype=\"int8\")\n",
        "\n",
        "\n",
        "\n",
        "X = np.concatenate((tumor_imgs_croped_yes, tumor_imgs_croped_no), axis=0)\n",
        "y = np.concatenate((y_yes, y_no), axis=0)\n",
        "print(X.shape)\n",
        "\n",
        "d1, d2, d3 = X.shape\n",
        "\n",
        "X = X.reshape((d1, d2 * d3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzDuZ5hklshL",
        "outputId": "ceec0c5f-9178-4dfe-9660-17c9cdec84bd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(245, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "\n",
        "# scale data before train model\n",
        "scaler_ = StandardScaler()\n",
        "X_train_sc = scaler_.fit_transform(X_train)\n",
        "X_test_sc = scaler_.transform(X_test)\n",
        "\n",
        "\n",
        "# random forest without pca\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_sc, y_train)\n",
        "y_predict_rf = rf_model.predict(X_test_sc)\n",
        "\n",
        "\n",
        "# SVC without pca\n",
        "svc_model = SVC(kernel=\"linear\")\n",
        "svc_model.fit(X_train_sc, y_train)\n",
        "y_predict_svc = svc_model.predict(X_test_sc)\n",
        "\n",
        "# PCA\n",
        "data_pca = PCA(n_components=12)\n",
        "pca_components = data_pca.fit(X_train_sc)\n",
        "X_train_pca = pca_components.fit_transform(X_train_sc)\n",
        "X_test_pca = pca_components.transform(X_test_sc)\n",
        "\n",
        "# KernelPCA\n",
        "data_kpca = KernelPCA()\n",
        "kpca_components = data_kpca.fit(X_train_sc)\n",
        "X_train_kpca = kpca_components.fit_transform(X_train_sc)\n",
        "X_test_kpca = kpca_components.transform(X_test_sc)\n",
        "\n",
        "\n",
        "# RandomForest With PCA\n",
        "rf_model_pca = RandomForestClassifier()\n",
        "rf_model_pca.fit(X_train_pca, y_train)\n",
        "y_predict_rf_pca = rf_model_pca.predict(X_test_pca)\n",
        "\n",
        "# SVC With PCA\n",
        "svc_model_pca = SVC(kernel=\"linear\")\n",
        "svc_model.fit(X_train_pca, y_train)\n",
        "y_predict_pca = svc_model.predict(X_test_pca)\n",
        "\n",
        "\n",
        "# RandomForest With KernelPCA\n",
        "rf_model_kpca = RandomForestClassifier()\n",
        "rf_model_kpca.fit(X_train_kpca, y_train)\n",
        "y_predict_rf_kpca = rf_model_kpca.predict(X_test_kpca)\n",
        "\n",
        "# SVC With KernelPCA\n",
        "svc_model_kpca = SVC(kernel=\"linear\")\n",
        "svc_model.fit(X_train_kpca, y_train)\n",
        "y_predict_kpca = svc_model.predict(X_test_kpca)\n",
        "\n",
        "\n",
        "print(\"SVC without PCA: \", accuracy_score(y_test, y_predict_svc))\n",
        "print(\"SVC with PCA: \", accuracy_score(y_test, y_predict_pca))\n",
        "\n",
        "print(\"SVC without PCA:\")\n",
        "print(classification_report(y_test, y_predict_svc))\n",
        "print(\"SVC with PCA:\")\n",
        "print(classification_report(y_test, y_predict_pca))\n",
        "\n",
        "\n",
        "print(\"RandomForest without PCA:\")\n",
        "print(classification_report(y_test, y_predict_rf))\n",
        "\n",
        "print(\"RandomForest with PCA:\")\n",
        "print(classification_report(y_test, y_predict_rf_pca))\n",
        "\n",
        "\n",
        "print(\"RandomForest without KPCA:\")\n",
        "print(classification_report(y_test, y_predict_rf_kpca))\n",
        "\n",
        "print(\"SVC with KPCA:\")\n",
        "print(classification_report(y_test, y_predict_kpca))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBSMSirelsXy",
        "outputId": "db967525-eb5f-4ecb-ea67-6a436cf8c254"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC without PCA:  0.7959183673469388\n",
            "SVC with PCA:  0.6122448979591837\n",
            "SVC without PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.83      0.75        18\n",
            "           1       0.89      0.77      0.83        31\n",
            "\n",
            "    accuracy                           0.80        49\n",
            "   macro avg       0.79      0.80      0.79        49\n",
            "weighted avg       0.81      0.80      0.80        49\n",
            "\n",
            "SVC with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.28      0.34        18\n",
            "           1       0.66      0.81      0.72        31\n",
            "\n",
            "    accuracy                           0.61        49\n",
            "   macro avg       0.56      0.54      0.53        49\n",
            "weighted avg       0.58      0.61      0.59        49\n",
            "\n",
            "RandomForest without PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.44      0.50        18\n",
            "           1       0.71      0.81      0.76        31\n",
            "\n",
            "    accuracy                           0.67        49\n",
            "   macro avg       0.64      0.63      0.63        49\n",
            "weighted avg       0.66      0.67      0.66        49\n",
            "\n",
            "RandomForest with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.61      0.69        18\n",
            "           1       0.80      0.90      0.85        31\n",
            "\n",
            "    accuracy                           0.80        49\n",
            "   macro avg       0.79      0.76      0.77        49\n",
            "weighted avg       0.79      0.80      0.79        49\n",
            "\n",
            "RandomForest without KPCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.22      0.33        18\n",
            "           1       0.67      0.94      0.78        31\n",
            "\n",
            "    accuracy                           0.67        49\n",
            "   macro avg       0.67      0.58      0.56        49\n",
            "weighted avg       0.67      0.67      0.62        49\n",
            "\n",
            "SVC with KPCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.83      0.75        18\n",
            "           1       0.89      0.77      0.83        31\n",
            "\n",
            "    accuracy                           0.80        49\n",
            "   macro avg       0.79      0.80      0.79        49\n",
            "weighted avg       0.81      0.80      0.80        49\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j_t_9RxaQRB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "without crop function"
      ],
      "metadata": {
        "id": "aViMpUXAdyY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ext = ['jpg', 'JPG', 'pnp', 'jpeg']\n",
        "\n",
        "def get_files(path_, ext):\n",
        "    temp_paths = []\n",
        "    [temp_paths.extend(glob.glob(path_ + '*.' + e)) for e in ext]\n",
        "    return temp_paths\n",
        "\n",
        "files_yes = get_files('yes/', ext)\n",
        "files_no = get_files('no/', ext)\n",
        "\n",
        "\n",
        "def read_files(files):\n",
        "    temp_images = []\n",
        "    for file in files:\n",
        "        temp_img = cv2.imread(file)\n",
        "        if temp_img is not None:\n",
        "            temp_images.append(temp_img)\n",
        "    return temp_images\n",
        "\n",
        "tumor_imgs_yes = read_files(files_yes)\n",
        "tumor_imgs_no = read_files(files_no)\n",
        "\n",
        "tumor_imgs_pp_yes = []\n",
        "tumor_imgs_pp_no = []\n",
        "\n",
        "\n",
        "for image in tumor_imgs_yes:\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image_resize = cv2.resize(gray, (128, 128))\n",
        "  tumor_imgs_pp_yes.append(image_resize)\n",
        "\n",
        "\n",
        "for image in tumor_imgs_no:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image_resize = cv2.resize(gray, (128, 128))\n",
        "    tumor_imgs_pp_no.append(image_resize)\n",
        "\n",
        "\n",
        "y_yes = np.ones(len(tumor_imgs_pp_yes), dtype=\"int8\")\n",
        "y_no = np.zeros(len(tumor_imgs_pp_no), dtype=\"int8\")\n",
        "\n",
        "\n",
        "\n",
        "X = np.concatenate((tumor_imgs_pp_yes, tumor_imgs_pp_no), axis=0)\n",
        "y = np.concatenate((y_yes, y_no), axis=0)\n",
        "print(X.shape)\n",
        "\n",
        "d1, d2, d3 = X.shape\n",
        "\n",
        "X = X.reshape((d1, d2 * d3))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "\n",
        "# scale data before train model\n",
        "scaler_ = StandardScaler()\n",
        "X_train_sc = scaler_.fit_transform(X_train)\n",
        "X_test_sc = scaler_.transform(X_test)\n",
        "\n",
        "\n",
        "# random forest without pca\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_sc, y_train)\n",
        "y_predict_rf = rf_model.predict(X_test_sc)\n",
        "\n",
        "\n",
        "# SVC without pca\n",
        "svc_model = SVC(kernel=\"linear\")\n",
        "svc_model.fit(X_train_sc, y_train)\n",
        "y_predict_svc = svc_model.predict(X_test_sc)\n",
        "\n",
        "# PCA\n",
        "data_pca = PCA(n_components=12)\n",
        "pca_components = data_pca.fit(X_train_sc)\n",
        "X_train_pca = pca_components.fit_transform(X_train_sc)\n",
        "X_test_pca = pca_components.transform(X_test_sc)\n",
        "\n",
        "# KernelPCA\n",
        "data_kpca = KernelPCA()\n",
        "kpca_components = data_kpca.fit(X_train_sc)\n",
        "X_train_kpca = kpca_components.fit_transform(X_train_sc)\n",
        "X_test_kpca = kpca_components.transform(X_test_sc)\n",
        "\n",
        "\n",
        "# RandomForest With PCA\n",
        "rf_model_pca = RandomForestClassifier()\n",
        "rf_model_pca.fit(X_train_pca, y_train)\n",
        "y_predict_rf_pca = rf_model_pca.predict(X_test_pca)\n",
        "\n",
        "# SVC With PCA\n",
        "svc_model_pca = SVC(kernel=\"linear\")\n",
        "svc_model.fit(X_train_pca, y_train)\n",
        "y_predict_pca = svc_model.predict(X_test_pca)\n",
        "\n",
        "\n",
        "# RandomForest With KernelPCA\n",
        "rf_model_kpca = RandomForestClassifier()\n",
        "rf_model_kpca.fit(X_train_kpca, y_train)\n",
        "y_predict_rf_kpca = rf_model_kpca.predict(X_test_kpca)\n",
        "\n",
        "# SVC With KernelPCA\n",
        "svc_model_kpca = SVC(kernel=\"linear\")\n",
        "svc_model.fit(X_train_kpca, y_train)\n",
        "y_predict_kpca = svc_model.predict(X_test_kpca)\n",
        "\n",
        "\n",
        "print(\"without PCA: \", accuracy_score(y_test, y_predict_svc))\n",
        "print(\"with PCA: \", accuracy_score(y_test, y_predict_pca))\n",
        "\n",
        "print(\"without PCA:\")\n",
        "print(classification_report(y_test, y_predict_svc))\n",
        "print(\"with PCA:\")\n",
        "print(classification_report(y_test, y_predict_pca))\n",
        "\n",
        "\n",
        "print(\"RandomForest without PCA:\")\n",
        "print(classification_report(y_test, y_predict_rf))\n",
        "\n",
        "print(\"RandomForest with PCA:\")\n",
        "print(classification_report(y_test, y_predict_rf_pca))\n",
        "\n",
        "\n",
        "print(\"RandomForest without KPCA:\")\n",
        "print(classification_report(y_test, y_predict_rf_kpca))\n",
        "\n",
        "print(\"SVC with KPCA:\")\n",
        "print(classification_report(y_test, y_predict_kpca))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MTD_XQ1db4_",
        "outputId": "7cbdab76-6773-41a8-c419-2904f6aef7c7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(245, 128, 128)\n",
            "without PCA:  0.7755102040816326\n",
            "with PCA:  0.7346938775510204\n",
            "without PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.67      0.69        18\n",
            "           1       0.81      0.84      0.83        31\n",
            "\n",
            "    accuracy                           0.78        49\n",
            "   macro avg       0.76      0.75      0.76        49\n",
            "weighted avg       0.77      0.78      0.77        49\n",
            "\n",
            "with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.56      0.61        18\n",
            "           1       0.76      0.84      0.80        31\n",
            "\n",
            "    accuracy                           0.73        49\n",
            "   macro avg       0.72      0.70      0.70        49\n",
            "weighted avg       0.73      0.73      0.73        49\n",
            "\n",
            "RandomForest without PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.61      0.65        18\n",
            "           1       0.79      0.84      0.81        31\n",
            "\n",
            "    accuracy                           0.76        49\n",
            "   macro avg       0.74      0.72      0.73        49\n",
            "weighted avg       0.75      0.76      0.75        49\n",
            "\n",
            "RandomForest with PCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.72      0.76        18\n",
            "           1       0.85      0.90      0.88        31\n",
            "\n",
            "    accuracy                           0.84        49\n",
            "   macro avg       0.83      0.81      0.82        49\n",
            "weighted avg       0.84      0.84      0.83        49\n",
            "\n",
            "RandomForest without KPCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.78      0.64        18\n",
            "           1       0.83      0.61      0.70        31\n",
            "\n",
            "    accuracy                           0.67        49\n",
            "   macro avg       0.68      0.70      0.67        49\n",
            "weighted avg       0.72      0.67      0.68        49\n",
            "\n",
            "SVC with KPCA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.67      0.69        18\n",
            "           1       0.81      0.84      0.83        31\n",
            "\n",
            "    accuracy                           0.78        49\n",
            "   macro avg       0.76      0.75      0.76        49\n",
            "weighted avg       0.77      0.78      0.77        49\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try CNN Model to Predict**"
      ],
      "metadata": {
        "id": "1PuxkVJMscqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "h19rQ6sKsYM-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/tumor_data\", \n",
        "    labels='inferred',\n",
        "    label_mode=\"int\",\n",
        "    color_mode='rgb',\n",
        "    # color_mode='bgr',\n",
        "    batch_size=32,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True,\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=46,\n",
        "    crop_to_aspect_ratio=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3UQWP3Axw0v",
        "outputId": "24683952-c384-4f94-a7cb-1f7a10016343"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 253 files belonging to 2 classes.\n",
            "Using 25 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(128, 128, 3))\n",
        "x = keras.layers.Rescaling(1./255)(inputs)\n",
        "x = keras.layers.Conv2D(filters=16, kernel_size=3, activation=\"selu\")(x) \n",
        "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"elu\")(x) \n",
        "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"tanh\")(x) \n",
        "x = keras.layers.Flatten()(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "hNMui4xUsYKg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "fitted_model =model.fit(train_dataset,epochs=15)"
      ],
      "metadata": {
        "id": "b27ufFKqsYDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fee34f9-248e-4377-9ae0-2fc6ffac0c95"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6638 - accuracy: 0.7200\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 1.7888 - accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.4056 - accuracy: 0.8800\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.7522 - accuracy: 0.4800\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.3717 - accuracy: 0.8800\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.5034 - accuracy: 0.6800\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.4942 - accuracy: 0.6800\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.3047 - accuracy: 0.8800\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.2605 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 0.2945 - accuracy: 0.8800\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.2771 - accuracy: 0.8800\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.2177 - accuracy: 0.9200\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.1689 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.1489 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.1469 - accuracy: 0.9600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "YMxuwYylJGLS",
        "outputId": "c8d9ab14-bf9e-4090-f908-4085c8f172f3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.1447 - accuracy: 0.9600\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1315 - accuracy: 0.9600\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.1097 - accuracy: 1.0000\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.0879 - accuracy: 1.0000\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.0724 - accuracy: 1.0000\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.0644 - accuracy: 1.0000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.0613 - accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 0.0541 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.0468 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0388 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0216 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-17cff97ceb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 987\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fitted_model.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZSjYGvoJMBo",
        "outputId": "cbc31591-9602-41b8-ecd2-135d06bccb78"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [0.6637853384017944, 1.7887747287750244, 0.4055693447589874, 0.7521761059761047, 0.3716881573200226, 0.5033863186836243, 0.4942244589328766, 0.3046582043170929, 0.2605043649673462, 0.2945373058319092, 0.27706441283226013, 0.21766792237758636, 0.16892407834529877, 0.14894667267799377, 0.14693765342235565], 'accuracy': [0.7200000286102295, 0.5199999809265137, 0.8799999952316284, 0.47999998927116394, 0.8799999952316284, 0.6800000071525574, 0.6800000071525574, 0.8799999952316284, 1.0, 0.8799999952316284, 0.8799999952316284, 0.9200000166893005, 1.0, 1.0, 0.9599999785423279]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdzSkj20TOi4",
        "outputId": "54e27a35-819b-4cdd-b884-62f46c21684b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.History object at 0x7fc46007a690>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C2SU565JVl_",
        "outputId": "0fbbf467-1e21-44a3-b85d-5b5027855371"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 126, 126, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 63, 63, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 50177     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73,761\n",
            "Trainable params: 73,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}
